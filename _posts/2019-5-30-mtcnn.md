---
layout: post
title: Multi-task Cascade Convolutional Network (MTCNN) 
subtitle: Kiến trúc và cách hoạt động của MTCNN, một trong những mạng convolutional hoạt động tốt nhất trong face detection hiện nay.
tags: []
comments: true
---
*Multi-task Cascade Convolutional Network (MTCNN) được sử dụng rất phổ biến khi đề cập tớt face detection, bởi độ chính xác cao của nó. Hôm nay mình sẽ giới thiệu với mọi người về kiến trúc cơ bản nhất của mạng này và cách nó hoạt động.* 

MTCNN hoạt động theo 3 stages, tại mỗi stage sẽ có một mạng neural riêng lần lượt là : P-Net, R-Net và O-Net. Chúng ta cùng xem xét từng stage và mạng neural lần lượt.

!(Cấu trúc mạng MTCNN. Có 3 stages chính, mỗi stage có một mạng neural tương ứng)[https://images.viblo.asia/34406778-660d-4bbf-918b-a087e193eba6.png]

##Stage 1
Việc đầu tiên cần làm hiển nhiên là đưa một bức ảnh làm đầu vào của mạng neural, ở stage 1 đó là P-Net. Trong model này, chúng ta một tạo ra các ***image pyramid*** (kim tự tháp hình ảnh) để xác định khuôn mặt với tất cả các kích cỡ khác nhau. Nói cách khác là chúng ta muốn tạo ra nhiều bản sao của cùng một bức ảnh ở nhiều kích thước khác nhau, rồi tiến hành tìm kiếm nhiều khuôn mặt với kích thước tương ứng trong mỗi bức ảnh. 

!(Image Pyramid)[https://cdn-images-1.medium.com/max/800/1*JH-L5EmTqj_fHEcXnzZT5Q.png]

Tại P-Net, thuật toán sử dụng 1 kernel 12x12 chạy qua tất cả các phần của bức hình để tìm kiếm khuôn mặt. Nó bắt đầu từ phần  góc trên bên trái của bức ảnh với tọa độ từ (0,0) đến (12,12). Phần này của bức ảnh được đưa qua P-Net, rồi sẽ trả về tọa độ của một ***bounding box*** nếu nó cho rằng có mặt nguời xuất hiện. Rồi cứ thế nó sẽ lặp lại quá trình trên với phần có tọa độ (0+2a, 0+2b) đến (12+2a, 12+2b), dịch kernel 12x12 2 pixels sang phải hoặc xuống dưới cùng một lúc. Khoảng cách này được gói là ***stride*** nếu bạn chưa biết, chính là số pixels mà kernel dịch chuyển mỗi lần.

Stride 2 sẽ giúp chúng ta giảm thiểu được chi phí tính toán mà không làm mất đi độ chính xác của quá trình detect. Vì hầu hết các khuôn mặt thì đều có kích thước lớn hơn 2 pixels khá nhiều, nên gần như không thể xảy ra việc kernel sẽ bỏ sót một khuôn mặt nào đó chỉ bởi việc dịch chuyển 2 pixels, trừ khi nó ở rất xa trong bức ảnh, và như thế thì mắt người cũng khó mà xác định được. Đồng thời thì máy tính, hay bất cứ thiết bị nào mà bạn đang dùng để chạy model, có thể giảm được khối lượng cần tính toán đi 4 lần, giúp cho model có thể inference nhanh hơn và tiết kiệm bộ nhớ hơn.

Nhược điểm duy nhất chính là việc chúng ta phải tính toán lại tất cả các dữ kiện liên quan đến stride. Ví dụ, nếu một kernel xác định được một khuôn mặt sau khi di chuyển một bước sang bên phải, chỉ số đầu ra sẽ cho chúng ta biết tọa độ góc trên bên trái của kernel đó tại (1,0). Tuy nhiên, do stride là 2, chúng ta sẽ phải nhân chỉ với 2 để được tọa độ chính xác: (2,0).

Mỗi kernel sẽ nhỏ hơn nếu nằm trong một bức ảnh lớn hơn, do đó nó sẽ tìm được các khuôn mặt nhỏ hơn trong bức ảnh có kích thước lớn hơn. Tương tự, kernel sẽ lớn hơn nếu nằm trong một bức ảnh có kích thước nhỏ hơn, do đó có thể tìm được khuôn mặt to trong những bức ảnh kích thước nhỏ.

!(Stage 1: P-Net)[https://images.viblo.asia/c2ad8543-8c46-4485-a92c-ca3a8b893b7a.png]

Sau lớp convolution thứ 3, mạng chia thành 2 lớp. Convolution 4-1 đưa ra xác suất của một khuôn mặt nằm trong mỗi bounding boxes, và Convolution 4-2 cung cấp tọa độ của các bounding boxes.

!()[https://www.youtube.com/watch?time_continue=18&v=w4tigQn-7Jw]
